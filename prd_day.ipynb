{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ece94c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy.ndimage import rotate\n",
    "from torch.distributions.uniform import Uniform\n",
    "from torch.distributions.normal import Normal\n",
    "from preprocessing import preprocess_graph, construct_feed_dict, sparse_to_tuple, mask_test_edges\n",
    "import scipy.sparse as sp\n",
    "from scipy.linalg import block_diag\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "import tarfile\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import time\n",
    "from torch_scatter import scatter_mean, scatter_max, scatter_add\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import networkx as nx\n",
    "import scipy.io as sio\n",
    "import torch_scatter\n",
    "import inspect\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "import copy\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib.ticker import MaxNLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaa86b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read 10 gml files\n",
    "mypath = \"../graphml/day/\"\n",
    "file_list = [f for f in listdir(mypath) if (isfile(join(mypath, f)) and  f.endswith('bz2'))]\n",
    "file_list = sorted(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7833cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_files(file_list, filename, num_files, hop):\n",
    "    if filename not in file_list:\n",
    "        raise ValueError(\"Target filename not found in the list\")\n",
    "    \n",
    "    target_index = file_list.index(filename)\n",
    "    \n",
    "    selected_indices = [target_index]\n",
    "    current_index = target_index\n",
    "    while len(selected_indices) < num_files:\n",
    "        current_index -= hop\n",
    "        if current_index < 0:\n",
    "            break\n",
    "        selected_indices.append(current_index)\n",
    "    \n",
    "    selected_indices = selected_indices[::-1]  # Reverse the order\n",
    "    \n",
    "    selected_files = [file_list[idx] for idx in selected_indices]\n",
    "    return selected_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6ca3c8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_day = \"2012-03-05\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1df4045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = select_files(file_list, select_day+'.graphml.bz2',30, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8f6e7526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# union set of all nodes\n",
    "g = []\n",
    "nodes = sorted(list(nx.read_graphml(mypath + files[-1]).nodes))\n",
    "for i in range(30):\n",
    "    gi = nx.read_graphml(mypath + files[i])\n",
    "    g.append(gi) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0dac2f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for week month year\n",
    "def find_edges_in_nodes(node_list, graph_list):\n",
    "    result_edges = []\n",
    "    # traverse the interval\n",
    "    for graph in graph_list:\n",
    "        # traverse the edges\n",
    "        for edge in graph.edges():\n",
    "            source, target = edge\n",
    "            if source in node_list and target in node_list:\n",
    "                result_edges.append(edge)\n",
    "    \n",
    "    return result_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04608b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate different adj matrices for dfifferent snapshots with their edges \n",
    "\n",
    "adj = []\n",
    "for i in range(30):\n",
    "    graph = nx.Graph()\n",
    "    graph.add_nodes_from(nodes)\n",
    "    graph.add_edges_from(find_edges_in_nodes(nodes, [g[i]]))\n",
    "    if (graph.number_of_edges() < 20):\n",
    "        continue\n",
    "    A = nx.adjacency_matrix(graph).astype(np.uint8)\n",
    "    adj.append(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "47625354",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adj_tensor = []\n",
    "\n",
    "for i in range(len(adj)):\n",
    "    adj_tensor.append(torch.tensor(adj[i].toarray()).to(torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7fe759fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<8701x8701 sparse array of type '<class 'numpy.uint8'>'\n",
       " \twith 2180 stored elements in Compressed Sparse Row format>,\n",
       " <8701x8701 sparse array of type '<class 'numpy.uint8'>'\n",
       " \twith 2146 stored elements in Compressed Sparse Row format>,\n",
       " <8701x8701 sparse array of type '<class 'numpy.uint8'>'\n",
       " \twith 2250 stored elements in Compressed Sparse Row format>,\n",
       " <8701x8701 sparse array of type '<class 'numpy.uint8'>'\n",
       " \twith 2106 stored elements in Compressed Sparse Row format>,\n",
       " <8701x8701 sparse array of type '<class 'numpy.uint8'>'\n",
       " \twith 2416 stored elements in Compressed Sparse Row format>,\n",
       " <8701x8701 sparse array of type '<class 'numpy.uint8'>'\n",
       " \twith 2216 stored elements in Compressed Sparse Row format>,\n",
       " <8701x8701 sparse array of type '<class 'numpy.uint8'>'\n",
       " \twith 2328 stored elements in Compressed Sparse Row format>,\n",
       " <8701x8701 sparse array of type '<class 'numpy.uint8'>'\n",
       " \twith 2374 stored elements in Compressed Sparse Row format>,\n",
       " <8701x8701 sparse array of type '<class 'numpy.uint8'>'\n",
       " \twith 2414 stored elements in Compressed Sparse Row format>,\n",
       " <8701x8701 sparse array of type '<class 'numpy.uint8'>'\n",
       " \twith 2086 stored elements in Compressed Sparse Row format>,\n",
       " <8701x8701 sparse array of type '<class 'numpy.uint8'>'\n",
       " \twith 2640 stored elements in Compressed Sparse Row format>,\n",
       " <8701x8701 sparse array of type '<class 'numpy.uint8'>'\n",
       " \twith 2534 stored elements in Compressed Sparse Row format>,\n",
       " <8701x8701 sparse array of type '<class 'numpy.uint8'>'\n",
       " \twith 2162 stored elements in Compressed Sparse Row format>,\n",
       " <8701x8701 sparse array of type '<class 'numpy.uint8'>'\n",
       " \twith 2980 stored elements in Compressed Sparse Row format>,\n",
       " <8701x8701 sparse array of type '<class 'numpy.uint8'>'\n",
       " \twith 2332 stored elements in Compressed Sparse Row format>,\n",
       " <8701x8701 sparse array of type '<class 'numpy.uint8'>'\n",
       " \twith 2408 stored elements in Compressed Sparse Row format>,\n",
       " <8701x8701 sparse array of type '<class 'numpy.uint8'>'\n",
       " \twith 2610 stored elements in Compressed Sparse Row format>,\n",
       " <8701x8701 sparse array of type '<class 'numpy.uint8'>'\n",
       " \twith 2780 stored elements in Compressed Sparse Row format>,\n",
       " <8701x8701 sparse array of type '<class 'numpy.uint8'>'\n",
       " \twith 2856 stored elements in Compressed Sparse Row format>,\n",
       " <8701x8701 sparse array of type '<class 'numpy.uint8'>'\n",
       " \twith 2582 stored elements in Compressed Sparse Row format>,\n",
       " <8701x8701 sparse array of type '<class 'numpy.uint8'>'\n",
       " \twith 2762 stored elements in Compressed Sparse Row format>,\n",
       " <8701x8701 sparse array of type '<class 'numpy.uint8'>'\n",
       " \twith 2786 stored elements in Compressed Sparse Row format>,\n",
       " <8701x8701 sparse array of type '<class 'numpy.uint8'>'\n",
       " \twith 2906 stored elements in Compressed Sparse Row format>,\n",
       " <8701x8701 sparse array of type '<class 'numpy.uint8'>'\n",
       " \twith 2828 stored elements in Compressed Sparse Row format>,\n",
       " <8701x8701 sparse array of type '<class 'numpy.uint8'>'\n",
       " \twith 2876 stored elements in Compressed Sparse Row format>,\n",
       " <8701x8701 sparse array of type '<class 'numpy.uint8'>'\n",
       " \twith 3082 stored elements in Compressed Sparse Row format>,\n",
       " <8701x8701 sparse array of type '<class 'numpy.uint8'>'\n",
       " \twith 3728 stored elements in Compressed Sparse Row format>,\n",
       " <8701x8701 sparse array of type '<class 'numpy.uint8'>'\n",
       " \twith 3222 stored elements in Compressed Sparse Row format>,\n",
       " <8701x8701 sparse array of type '<class 'numpy.uint8'>'\n",
       " \twith 3810 stored elements in Compressed Sparse Row format>,\n",
       " <8701x8701 sparse array of type '<class 'numpy.uint8'>'\n",
       " \twith 23782 stored elements in Compressed Sparse Row format>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7beaa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/eva/Downloads/FS23/MasterProject/code/adj_day_50_2011_10_01.pickle', 'rb') as handle:\n",
    "    adj = pickle.load(handle,encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49fdd359",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Users/eva/Downloads/FS23/MasterProject/code/adj_day_30_2012_04_24.pickle'\n",
    "\n",
    "# Writing (pickling) the list to a file\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(adj, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eef1e3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 3\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2069c274",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:56: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:62: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:56: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:62: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/var/folders/7r/ldjcp71d7rl9t4lb3_r0llxc0000gn/T/ipykernel_94583/3553926969.py:56: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  fill_value = -1e38 if name is 'max' else 0\n",
      "/var/folders/7r/ldjcp71d7rl9t4lb3_r0llxc0000gn/T/ipykernel_94583/3553926969.py:62: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if name is 'max':\n"
     ]
    }
   ],
   "source": [
    "def uniform(size, tensor):\n",
    "    stdv = 1.0 / math.sqrt(size)\n",
    "    if tensor is not None:\n",
    "        tensor.data.uniform_(-stdv, stdv)\n",
    "\n",
    "\n",
    "def glorot(tensor):\n",
    "    stdv = math.sqrt(6.0 / (tensor.size(0) + tensor.size(1)))\n",
    "    if tensor is not None:\n",
    "        tensor.data.uniform_(-stdv, stdv)\n",
    "\n",
    "\n",
    "def zeros(tensor):\n",
    "    if tensor is not None:\n",
    "        tensor.data.fill_(0)\n",
    "\n",
    "\n",
    "def ones(tensor):\n",
    "    if tensor is not None:\n",
    "        tensor.data.fill_(1)\n",
    "\n",
    "\n",
    "def reset(nn):\n",
    "    def _reset(item):\n",
    "        if hasattr(item, 'reset_parameters'):\n",
    "            item.reset_parameters()\n",
    "\n",
    "    if nn is not None:\n",
    "        if hasattr(nn, 'children') and len(list(nn.children())) > 0:\n",
    "            for item in nn.children():\n",
    "                _reset(item)\n",
    "        else:\n",
    "            _reset(nn)\n",
    "\n",
    "\n",
    "def scatter_(name, src, index, dim_size=None):\n",
    "\n",
    "    assert name in ['add', 'mean', 'max']\n",
    "\n",
    "    op = getattr(torch_scatter, 'scatter_{}'.format(name))\n",
    "    fill_value = -1e38 if name is 'max' else 0\n",
    "\n",
    "    out = op(src, index, 0, None, dim_size, fill_value)\n",
    "    if isinstance(out, tuple):\n",
    "        out = out[0]\n",
    "\n",
    "    if name is 'max':\n",
    "        out[out == fill_value] = 0\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72a4f631",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MessagePassing(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, aggr='add'):\n",
    "        super(MessagePassing, self).__init__()\n",
    "\n",
    "        self.message_args = inspect.getargspec(self.message)[0][1:]\n",
    "        self.update_args = inspect.getargspec(self.update)[0][2:]\n",
    "\n",
    "    def propagate(self, aggr, edge_index, **kwargs):\n",
    "\n",
    "        assert aggr in ['add', 'mean', 'max']\n",
    "        kwargs['edge_index'] = edge_index\n",
    "\n",
    "        size = None\n",
    "        message_args = []\n",
    "        for arg in self.message_args:\n",
    "            if arg[-2:] == '_i':\n",
    "                tmp = kwargs[arg[:-2]]\n",
    "                size = tmp.size(0)\n",
    "                message_args.append(tmp[edge_index[0]])\n",
    "            elif arg[-2:] == '_j':\n",
    "                tmp = kwargs[arg[:-2]]\n",
    "                size = tmp.size(0)\n",
    "                message_args.append(tmp[edge_index[1]])\n",
    "            else:\n",
    "                message_args.append(kwargs[arg])\n",
    "\n",
    "        update_args = [kwargs[arg] for arg in self.update_args]\n",
    "\n",
    "        out = self.message(*message_args)\n",
    "        out = scatter_(aggr, out, edge_index[0], dim_size=size)\n",
    "        out = self.update(out, *update_args)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j):  # pragma: no cover\n",
    "\n",
    "        return x_j\n",
    "\n",
    "    def update(self, aggr_out):  # pragma: no cover\n",
    "\n",
    "        return aggr_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ebe622f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuple_to_array(lot):\n",
    "    out = np.array(list(lot[0]))\n",
    "    for i in range(1, len(lot)):\n",
    "        out = np.vstack((out, np.array(list(lot[i]))))\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed07b12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_edges_prd(adjs_list):\n",
    "    adj_train_l, train_edges_l, val_edges_l = [], [], []\n",
    "    val_edges_false_l, test_edges_l, test_edges_false_l = [], [], []\n",
    "    edges_list = []\n",
    "    for i in range(0, len(adjs_list)):\n",
    "        # Function to build test set with 10% positive links\n",
    "        # NOTE: Splits are randomized and results might slightly deviate from reported numbers in the paper.\n",
    "        \n",
    "        adj = adjs_list[i]\n",
    "        # Remove diagonal elements\n",
    "        adj = adj - sp.dia_matrix((adj.diagonal()[np.newaxis], [0]), shape=adj.shape)\n",
    "        adj.eliminate_zeros()\n",
    "        # Check that diag is zero:\n",
    "        assert np.diag(adj.todense()).sum() == 0\n",
    "        \n",
    "        #Convert the upper triangular part of the adjacency matrix to a sparse matrix and extract the edges.\n",
    "        adj_triu = sp.triu(adj)\n",
    "        edges = sparse_to_tuple(adj_triu)[0]   # a half of all edges\n",
    "        edges_all = sparse_to_tuple(adj)[0]\n",
    "        num_test = int(np.floor(edges.shape[0] / 10))\n",
    "        num_val = int(np.floor(edges.shape[0] / 20))\n",
    "        \n",
    "        all_edge_idx = list(range(edges.shape[0]))  #convert the range object to a list before shuffling it\n",
    "        np.random.shuffle(all_edge_idx)\n",
    "        val_edge_idx = all_edge_idx[:num_val]\n",
    "        test_edge_idx = all_edge_idx[num_val:(num_val + num_test)]\n",
    "        test_edges = edges[test_edge_idx]\n",
    "        val_edges = edges[val_edge_idx]\n",
    "        train_edges = np.delete(edges, np.hstack([test_edge_idx, val_edge_idx]), axis=0)\n",
    "        \n",
    "        edges_list.append(edges)\n",
    "        \n",
    "        def ismember(a, b, tol=5):\n",
    "            rows_close = np.all(np.round(a - b[:, None], tol) == 0, axis=-1)\n",
    "            return np.any(rows_close)\n",
    "\n",
    "        test_edges_false = []\n",
    "        while len(test_edges_false) < len(test_edges):\n",
    "            idx_i = np.random.randint(0, adj.shape[0])\n",
    "            idx_j = np.random.randint(0, adj.shape[0])\n",
    "            if idx_i == idx_j or ismember([idx_i, idx_j], edges_all):\n",
    "                continue\n",
    "            if ismember([idx_j, idx_i],np.array(test_edges_false)) or ismember([idx_i, idx_j],np.array(test_edges_false)):\n",
    "                continue\n",
    "            test_edges_false.append([idx_i, idx_j])\n",
    "\n",
    "        val_edges_false = []\n",
    "        while len(val_edges_false) < len(val_edges):\n",
    "            idx_i = np.random.randint(0, adj.shape[0])\n",
    "            idx_j = np.random.randint(0, adj.shape[0])\n",
    "            if idx_i == idx_j:\n",
    "                continue\n",
    "            if ismember([idx_i, idx_j], train_edges) or ismember([idx_j, idx_i], train_edges):\n",
    "                continue\n",
    "            if ismember([idx_i, idx_j], val_edges) or ismember([idx_j, idx_i], val_edges):\n",
    "                continue\n",
    "            if ismember([idx_j, idx_i], np.array(val_edges_false)) or ismember([idx_i, idx_j], np.array(val_edges_false)):\n",
    "                continue\n",
    "            val_edges_false.append([idx_i, idx_j])\n",
    "\n",
    "        assert ~ismember(test_edges_false, edges_all)\n",
    "        assert ~ismember(val_edges_false, edges_all)\n",
    "        assert ~ismember(val_edges, train_edges)\n",
    "        assert ~ismember(test_edges, train_edges)\n",
    "        assert ~ismember(val_edges, test_edges)\n",
    "\n",
    "        data = np.ones(train_edges.shape[0])\n",
    "\n",
    "        # Re-build adj matrix\n",
    "        adj_train = sp.csr_matrix((data, (train_edges[:, 0], train_edges[:, 1])), shape=adj.shape)\n",
    "        adj_train = adj_train + adj_train.T\n",
    "\n",
    "        adj_train_l.append(adj_train)\n",
    "        train_edges_l.append(train_edges)\n",
    "        val_edges_l.append(val_edges)\n",
    "        val_edges_false_l.append(val_edges_false)\n",
    "        test_edges_l.append(test_edges)\n",
    "        test_edges_false_l.append(test_edges_false)\n",
    "\n",
    "    # NOTE: these edge lists only contain single direction of edge!\n",
    "    return adj_train_l, train_edges_l, val_edges_l, val_edges_false_l, test_edges_l, test_edges_false_l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "476d9f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_time_list = adj\n",
    "adj_orig_dense_list = adj_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b3d29d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "07fa6ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_edges_ln, pos_edges_ln, false_edges_ln = mask_edges_prd(adj_time_list)\n",
    "outs = mask_edges_prd(adj_time_list)\n",
    "\n",
    "adj_train_l = outs[0]\n",
    "train_edges_l = outs[1]\n",
    "val_edges_l = outs[2]\n",
    "val_edges_false_l = outs[3]\n",
    "test_edges_l = outs[4]\n",
    "test_edges_false_l = outs[5]\n",
    "\n",
    "\n",
    "# creating edge list\n",
    "\n",
    "edge_idx_list = []\n",
    "\n",
    "for i in range(len(train_edges_l)):\n",
    "    edge_idx_list.append(torch.tensor(np.transpose(train_edges_l[i]), dtype=torch.long))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad235c4e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "133d8bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, act=F.relu, improved=True, bias=False):\n",
    "        super(GCNConv, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.improved = improved\n",
    "        self.act = act\n",
    "\n",
    "        self.weight = Parameter(torch.Tensor(in_channels, out_channels))\n",
    "\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        glorot(self.weight)\n",
    "        zeros(self.bias)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        if edge_weight is None:\n",
    "            edge_weight = torch.ones(\n",
    "                (edge_index.size(1), ), dtype=x.dtype, device=x.device)\n",
    "        edge_weight = edge_weight.view(-1)\n",
    "        assert edge_weight.size(0) == edge_index.size(1)\n",
    "\n",
    "        edge_index = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        loop_weight = torch.full(\n",
    "            (x.size(0), ),\n",
    "            1 if not self.improved else 2,\n",
    "            dtype=x.dtype,\n",
    "            device=x.device)\n",
    "        edge_weight = torch.cat([edge_weight, loop_weight], dim=0)\n",
    "\n",
    "        row, col = edge_index\n",
    "        deg = scatter_add(edge_weight, row, dim=0, dim_size=x.size(0))\n",
    "        deg_inv = deg.pow(-0.5)\n",
    "        deg_inv[deg_inv == float('inf')] = 0\n",
    "\n",
    "        norm = deg_inv[row] * edge_weight * deg_inv[col]\n",
    "\n",
    "        x = torch.matmul(x, self.weight)\n",
    "        out = self.propagate('add', edge_index, x=x, norm=norm)\n",
    "        return self.act(out)\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        return norm.view(-1, 1) * x_j\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        if self.bias is not None:\n",
    "            aggr_out = aggr_out + self.bias\n",
    "        return aggr_out\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({}, {})'.format(self.__class__.__name__, self.in_channels,\n",
    "                                   self.out_channels)\n",
    "\n",
    "\n",
    "class SAGEConv(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, pool='mean', act=F.relu, normalize=False, bias=False):\n",
    "        super(SAGEConv, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.normalize = normalize\n",
    "        self.weight = Parameter(torch.Tensor(self.in_channels, out_channels))\n",
    "        self.act = act\n",
    "        self.pool = pool\n",
    "        \n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        size = self.weight.size(0)\n",
    "        uniform(size, self.weight)\n",
    "        uniform(size, self.bias)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        edge_index, _ = remove_self_loops(edge_index)\n",
    "        edge_index = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        \n",
    "        x = x.unsqueeze(-1) if x.dim() == 1 else x\n",
    "        row, col = edge_index\n",
    "        \n",
    "        if self.pool == 'mean':\n",
    "            out = torch.matmul(x, self.weight)\n",
    "            if self.bias is not None:\n",
    "                out = out + self.bias\n",
    "            out = self.act(out)\n",
    "            out = scatter_mean(out[col], row, dim=0, dim_size=out.size(0))\n",
    "            \n",
    "        elif self.pool == 'max':\n",
    "            out = torch.matmul(x, self.weight)\n",
    "            if self.bias is not None:\n",
    "                out = out + self.bias\n",
    "            out = self.act(out)\n",
    "            out, _ = scatter_max(out[col], row, dim=0, dim_size=out.size(0))\n",
    "            \n",
    "        elif self.pool == 'add':\n",
    "            x = torch.matmul(x, self.weight)\n",
    "            if self.bias is not None:\n",
    "                out = out + self.bias\n",
    "            out = self.act(out)\n",
    "            out = scatter_add(x[col], row, dim=0, dim_size=x.size(0))\n",
    "        else:\n",
    "            print('pooling not defined!')\n",
    "                \n",
    "        if self.normalize:\n",
    "            out = F.normalize(out, p=2, dim=-1)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return '{}({}, {})'.format(self.__class__.__name__, self.in_channels, self.out_channels)\n",
    "\n",
    "class GINConv(torch.nn.Module):\n",
    "    def __init__(self, nn, eps=0, train_eps=False):\n",
    "        super(GINConv, self).__init__()\n",
    "        self.nn = nn\n",
    "        self.initial_eps = eps\n",
    "        if train_eps:\n",
    "            self.eps = torch.nn.Parameter(torch.Tensor([eps]))\n",
    "        else:\n",
    "            self.register_buffer('eps', torch.Tensor([eps]))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        reset(self.nn)\n",
    "        self.eps.data.fill_(self.initial_eps)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = x.unsqueeze(-1) if x.dim() == 1 else x\n",
    "        edge_index, _ = remove_self_loops(edge_index)\n",
    "        row, col = edge_index\n",
    "\n",
    "        out = scatter_add(x[col], row, dim=0, dim_size=x.size(0))\n",
    "        out = (1 + self.eps) * x + out\n",
    "        out = self.nn(out)\n",
    "        return out\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}(nn={})'.format(self.__class__.__name__, self.nn)\n",
    "\n",
    "class graph_gru_sage(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layer, bias=True):\n",
    "        super(graph_gru_sage, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layer = n_layer\n",
    "        \n",
    "        # gru weights\n",
    "        self.weight_xz = []\n",
    "        self.weight_hz = []\n",
    "        self.weight_xr = []\n",
    "        self.weight_hr = []\n",
    "        self.weight_xh = []\n",
    "        self.weight_hh = []\n",
    "        \n",
    "        for i in range(self.n_layer):\n",
    "            if i==0:\n",
    "                self.weight_xz.append(SAGEConv(input_size, hidden_size, act=lambda x:x, bias=bias))\n",
    "                self.weight_hz.append(SAGEConv(hidden_size, hidden_size, act=lambda x:x, bias=bias))\n",
    "                self.weight_xr.append(SAGEConv(input_size, hidden_size, act=lambda x:x, bias=bias))\n",
    "                self.weight_hr.append(SAGEConv(hidden_size, hidden_size, act=lambda x:x, bias=bias))\n",
    "                self.weight_xh.append(SAGEConv(input_size, hidden_size, act=lambda x:x, bias=bias))\n",
    "                self.weight_hh.append(SAGEConv(hidden_size, hidden_size, act=lambda x:x, bias=bias))\n",
    "            else:\n",
    "                self.weight_xz.append(SAGEConv(hidden_size, hidden_size, act=lambda x:x, bias=bias))\n",
    "                self.weight_hz.append(SAGEConv(hidden_size, hidden_size, act=lambda x:x, bias=bias))\n",
    "                self.weight_xr.append(SAGEConv(hidden_size, hidden_size, act=lambda x:x, bias=bias))\n",
    "                self.weight_hr.append(SAGEConv(hidden_size, hidden_size, act=lambda x:x, bias=bias))\n",
    "                self.weight_xh.append(SAGEConv(hidden_size, hidden_size, act=lambda x:x, bias=bias))\n",
    "                self.weight_hh.append(SAGEConv(hidden_size, hidden_size, act=lambda x:x, bias=bias))\n",
    "    \n",
    "    def forward(self, inp, edgidx, h):\n",
    "        h_out = torch.zeros(h.size())\n",
    "        for i in range(self.n_layer):\n",
    "            if i==0:\n",
    "                z_g = torch.sigmoid(self.weight_xz[i](inp, edgidx) + self.weight_hz[i](h[i], edgidx))\n",
    "                r_g = torch.sigmoid(self.weight_xr[i](inp, edgidx) + self.weight_hr[i](h[i], edgidx))\n",
    "                h_tilde_g = torch.tanh(self.weight_xh[i](inp, edgidx) + self.weight_hh[i](r_g * h[i], edgidx))\n",
    "                h_out[i] = z_g * h[i] + (1 - z_g) * h_tilde_g\n",
    "        #         out = self.decoder(h_t.view(1,-1))\n",
    "            else:\n",
    "                z_g = torch.sigmoid(self.weight_xz[i](h_out[i-1], edgidx) + self.weight_hz[i](h[i], edgidx))\n",
    "                r_g = torch.sigmoid(self.weight_xr[i](h_out[i-1], edgidx) + self.weight_hr[i](h[i], edgidx))\n",
    "                h_tilde_g = torch.tanh(self.weight_xh[i](h_out[i-1], edgidx) + self.weight_hh[i](r_g * h[i], edgidx))\n",
    "                h_out[i] = z_g * h[i] + (1 - z_g) * h_tilde_g\n",
    "        #         out = self.decoder(h_t.view(1,-1))\n",
    "        \n",
    "        out = h_out\n",
    "        return out, h_out\n",
    "\n",
    "\n",
    "class graph_gru_gcn(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layer, bias=True):\n",
    "        super(graph_gru_gcn, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layer = n_layer\n",
    "        \n",
    "        # gru weights\n",
    "        self.weight_xz = []\n",
    "        self.weight_hz = []\n",
    "        self.weight_xr = []  \n",
    "        self.weight_hr = []\n",
    "        self.weight_xh = []\n",
    "        self.weight_hh = []\n",
    "        \n",
    "        for i in range(self.n_layer):\n",
    "            if i==0:\n",
    "                self.weight_xz.append(GCNConv(input_size, hidden_size, act=lambda x:x, bias=bias))\n",
    "                self.weight_hz.append(GCNConv(hidden_size, hidden_size, act=lambda x:x, bias=bias))\n",
    "                self.weight_xr.append(GCNConv(input_size, hidden_size, act=lambda x:x, bias=bias))\n",
    "                self.weight_hr.append(GCNConv(hidden_size, hidden_size, act=lambda x:x, bias=bias))\n",
    "                self.weight_xh.append(GCNConv(input_size, hidden_size, act=lambda x:x, bias=bias))\n",
    "                self.weight_hh.append(GCNConv(hidden_size, hidden_size, act=lambda x:x, bias=bias))\n",
    "            else:\n",
    "                self.weight_xz.append(GCNConv(hidden_size, hidden_size, act=lambda x:x, bias=bias))\n",
    "                self.weight_hz.append(GCNConv(hidden_size, hidden_size, act=lambda x:x, bias=bias))\n",
    "                self.weight_xr.append(GCNConv(hidden_size, hidden_size, act=lambda x:x, bias=bias))\n",
    "                self.weight_hr.append(GCNConv(hidden_size, hidden_size, act=lambda x:x, bias=bias))\n",
    "                self.weight_xh.append(GCNConv(hidden_size, hidden_size, act=lambda x:x, bias=bias))\n",
    "                self.weight_hh.append(GCNConv(hidden_size, hidden_size, act=lambda x:x, bias=bias))\n",
    "    \n",
    "    def forward(self, inp, edgidx, h):\n",
    "        h_out = torch.zeros(h.size())\n",
    "        for i in range(self.n_layer):\n",
    "            if i==0:\n",
    "                z_g = torch.sigmoid(self.weight_xz[i](inp, edgidx) + self.weight_hz[i](h[i], edgidx))\n",
    "                r_g = torch.sigmoid(self.weight_xr[i](inp, edgidx) + self.weight_hr[i](h[i], edgidx))\n",
    "                h_tilde_g = torch.tanh(self.weight_xh[i](inp, edgidx) + self.weight_hh[i](r_g * h[i], edgidx))\n",
    "                h_out[i] = z_g * h[i] + (1 - z_g) * h_tilde_g\n",
    "        #         out = self.decoder(h_t.view(1,-1))\n",
    "            else:\n",
    "                z_g = torch.sigmoid(self.weight_xz[i](h_out[i-1], edgidx) + self.weight_hz[i](h[i], edgidx))\n",
    "                r_g = torch.sigmoid(self.weight_xr[i](h_out[i-1], edgidx) + self.weight_hr[i](h[i], edgidx))\n",
    "                h_tilde_g = torch.tanh(self.weight_xh[i](h_out[i-1], edgidx) + self.weight_hh[i](r_g * h[i], edgidx))\n",
    "                h_out[i] = z_g * h[i] + (1 - z_g) * h_tilde_g\n",
    "        #         out = self.decoder(h_t.view(1,-1))\n",
    "        \n",
    "        out = h_out\n",
    "        return out, h_out\n",
    "\n",
    "\n",
    "class InnerProductDecoder(nn.Module):\n",
    "    def __init__(self, act=torch.sigmoid, dropout=0.):\n",
    "        super(InnerProductDecoder, self).__init__()\n",
    "        \n",
    "        self.act = act\n",
    "        self.dropout = dropout\n",
    "    \n",
    "    def forward(self, inp):\n",
    "        inp = F.dropout(inp, self.dropout, training=self.training)\n",
    "        x = torch.transpose(inp, dim0=0, dim1=1)\n",
    "        x = torch.mm(inp, x)\n",
    "        return self.act(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "57872ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation function\n",
    "\n",
    "def get_roc_scores(edges_pos, edges_neg, adj_orig_dense_list, embs):\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    auc_scores = []\n",
    "    ap_scores = []\n",
    "#     acc_scores = []\n",
    "    \n",
    "    for i in range(len(edges_pos)):\n",
    "        # Predict on test set of edges\n",
    "        emb = embs[i].detach().numpy()\n",
    "        adj_rec = np.dot(emb, emb.T)\n",
    "        adj_orig_t = adj_orig_dense_list[i]\n",
    "        \n",
    "        preds = []\n",
    "        pos = []\n",
    "        for e in edges_pos[i]:\n",
    "            preds.append(sigmoid(adj_rec[e[0], e[1]]))\n",
    "            pos.append(adj_orig_t[e[0], e[1]])\n",
    "            \n",
    "        preds_neg = []\n",
    "        neg = []\n",
    "        for e in edges_neg[i]:\n",
    "            preds_neg.append(sigmoid(adj_rec[e[0], e[1]]))\n",
    "            neg.append(adj_orig_t[e[0], e[1]])\n",
    "        \n",
    "        preds_all = np.hstack([preds, preds_neg])\n",
    "        labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))]) \n",
    "        auc_scores.append(roc_auc_score(labels_all, preds_all))\n",
    "        ap_scores.append(average_precision_score(labels_all, preds_all))\n",
    "\n",
    "        \n",
    "    return auc_scores, ap_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dde88a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGRNN model\n",
    "\n",
    "class VGRNN(nn.Module):\n",
    "    def __init__(self, x_dim, h_dim, z_dim, n_layers, eps, conv='GCN', bias=False):\n",
    "        super(VGRNN, self).__init__()\n",
    "        \n",
    "        self.x_dim = x_dim\n",
    "        self.eps = eps\n",
    "        self.h_dim = h_dim\n",
    "        self.z_dim = z_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        if conv == 'GCN':\n",
    "            self.phi_x = nn.Sequential(nn.Linear(x_dim, h_dim), nn.ReLU())\n",
    "            self.phi_z = nn.Sequential(nn.Linear(z_dim, h_dim), nn.ReLU())\n",
    "            \n",
    "            self.enc = GCNConv(h_dim + h_dim, h_dim)            \n",
    "            self.enc_mean = GCNConv(h_dim, z_dim, act=lambda x:x)\n",
    "            self.enc_std = GCNConv(h_dim, z_dim, act=F.softplus)\n",
    "            \n",
    "            self.prior = nn.Sequential(nn.Linear(h_dim, h_dim), nn.ReLU())\n",
    "            self.prior_mean = nn.Sequential(nn.Linear(h_dim, z_dim))\n",
    "            self.prior_std = nn.Sequential(nn.Linear(h_dim, z_dim), nn.Softplus())\n",
    "            \n",
    "            self.rnn = graph_gru_gcn(h_dim + h_dim, h_dim, n_layers, bias)\n",
    "            \n",
    "        elif conv == 'SAGE':\n",
    "            self.phi_x = nn.Sequential(nn.Linear(x_dim, h_dim), nn.ReLU())\n",
    "            self.phi_z = nn.Sequential(nn.Linear(z_dim, h_dim), nn.ReLU())\n",
    "            \n",
    "            self.enc = SAGEConv(h_dim + h_dim, h_dim)\n",
    "            self.enc_mean = SAGEConv(h_dim, z_dim, act=lambda x:x)\n",
    "            self.enc_std = SAGEConv(h_dim, z_dim, act=F.softplus)\n",
    "            \n",
    "            self.prior = nn.Sequential(nn.Linear(h_dim, h_dim), nn.ReLU())\n",
    "            self.prior_mean = nn.Sequential(nn.Linear(h_dim, z_dim))\n",
    "            self.prior_std = nn.Sequential(nn.Linear(h_dim, z_dim), nn.Softplus())\n",
    "            \n",
    "            self.rnn = graph_gru_sage(h_dim + h_dim, h_dim, n_layers, bias)\n",
    "            \n",
    "        elif conv == 'GIN':\n",
    "            self.phi_x = nn.Sequential(nn.Linear(x_dim, h_dim), nn.ReLU())\n",
    "            self.phi_z = nn.Sequential(nn.Linear(z_dim, h_dim), nn.ReLU())\n",
    "            \n",
    "            self.enc = GINConv(nn.Sequential(nn.Linear(h_dim + h_dim, h_dim), nn.ReLU()))            \n",
    "            self.enc_mean = GINConv(nn.Sequential(nn.Linear(h_dim, z_dim)))\n",
    "            self.enc_std = GINConv(nn.Sequential(nn.Linear(h_dim, z_dim), nn.Softplus()))\n",
    "            \n",
    "            self.prior = nn.Sequential(nn.Linear(h_dim, h_dim), nn.ReLU())\n",
    "            self.prior_mean = nn.Sequential(nn.Linear(h_dim, z_dim))\n",
    "            self.prior_std = nn.Sequential(nn.Linear(h_dim, z_dim), nn.Softplus())\n",
    "            \n",
    "            self.rnn = graph_gru_gcn(h_dim + h_dim, h_dim, n_layers, bias)  \n",
    "    \n",
    "    def forward(self, x, edge_idx_list, adj_orig_dense_list, hidden_in=None):\n",
    "        assert len(adj_orig_dense_list) == len(edge_idx_list)\n",
    "        \n",
    "        kld_loss = 0\n",
    "        nll_loss = 0\n",
    "        all_enc_mean, all_enc_std = [], []\n",
    "        all_prior_mean, all_prior_std = [], []\n",
    "        all_dec_t, all_z_t = [], []\n",
    "        \n",
    "        if hidden_in is None:\n",
    "            h = Variable(torch.zeros(self.n_layers, x.size(1), self.h_dim))\n",
    "        else:\n",
    "            h = Variable(hidden_in)\n",
    "        \n",
    "        for t in range(x.size(0)):\n",
    "            phi_x_t = self.phi_x(x[t])\n",
    "            \n",
    "            #encoder\n",
    "            enc_t = self.enc(torch.cat([phi_x_t, h[-1]], 1), edge_idx_list[t])\n",
    "            enc_mean_t = self.enc_mean(enc_t, edge_idx_list[t])\n",
    "            enc_std_t = self.enc_std(enc_t, edge_idx_list[t])\n",
    "            \n",
    "            #prior\n",
    "            prior_t = self.prior(h[-1])\n",
    "            prior_mean_t = self.prior_mean(prior_t)\n",
    "            prior_std_t = self.prior_std(prior_t)\n",
    "            \n",
    "            #sampling and reparameterization\n",
    "            z_t = self._reparameterized_sample(enc_mean_t, enc_std_t)\n",
    "            phi_z_t = self.phi_z(z_t)\n",
    "            \n",
    "            #decoder\n",
    "            dec_t = self.dec(z_t)\n",
    "            \n",
    "            #recurrence\n",
    "            _, h = self.rnn(torch.cat([phi_x_t, phi_z_t], 1), edge_idx_list[t], h)\n",
    "            \n",
    "            nnodes = adj_orig_dense_list[t].size()[0]\n",
    "            enc_mean_t_sl = enc_mean_t[0:nnodes, :]\n",
    "            enc_std_t_sl = enc_std_t[0:nnodes, :]\n",
    "            prior_mean_t_sl = prior_mean_t[0:nnodes, :]\n",
    "            prior_std_t_sl = prior_std_t[0:nnodes, :]\n",
    "            dec_t_sl = dec_t[0:nnodes, 0:nnodes]\n",
    "            \n",
    "            #computing losses\n",
    "#             kld_loss += self._kld_gauss_zu(enc_mean_t, enc_std_t)\n",
    "            kld_loss += self._kld_gauss(enc_mean_t_sl, enc_std_t_sl, prior_mean_t_sl, prior_std_t_sl)\n",
    "            nll_loss += self._nll_bernoulli(dec_t_sl, adj_orig_dense_list[t])\n",
    "            \n",
    "            all_enc_std.append(enc_std_t_sl)\n",
    "            all_enc_mean.append(enc_mean_t_sl)\n",
    "            all_prior_mean.append(prior_mean_t_sl)\n",
    "            all_prior_std.append(prior_std_t_sl)\n",
    "            all_dec_t.append(dec_t_sl)\n",
    "            all_z_t.append(z_t)\n",
    "        \n",
    "        return kld_loss, nll_loss, all_enc_mean, all_prior_mean, h\n",
    "    \n",
    "    def dec(self, z):\n",
    "        outputs = InnerProductDecoder(act=lambda x:x)(z)\n",
    "        return outputs\n",
    "    \n",
    "    def reset_parameters(self, stdv=1e-1):\n",
    "        for weight in self.parameters():\n",
    "            weight.data.normal_(0, stdv)\n",
    "     \n",
    "    def _init_weights(self, stdv):\n",
    "        pass\n",
    "    \n",
    "    def _reparameterized_sample(self, mean, std):\n",
    "        eps1 = torch.FloatTensor(std.size()).normal_()\n",
    "        eps1 = Variable(eps1)\n",
    "        return eps1.mul(std).add_(mean)\n",
    "    \n",
    "    def _kld_gauss(self, mean_1, std_1, mean_2, std_2):\n",
    "        num_nodes = mean_1.size()[0]\n",
    "        kld_element =  (2 * torch.log(std_2 + self.eps) - 2 * torch.log(std_1 + self.eps) +\n",
    "                        (torch.pow(std_1 + self.eps ,2) + torch.pow(mean_1 - mean_2, 2)) / \n",
    "                        torch.pow(std_2 + self.eps ,2) - 1)\n",
    "        return (0.5 / num_nodes) * torch.mean(torch.sum(kld_element, dim=1), dim=0)\n",
    "    \n",
    "    def _kld_gauss_zu(self, mean_in, std_in):\n",
    "        num_nodes = mean_in.size()[0]\n",
    "        std_log = torch.log(std_in + self.eps)\n",
    "        kld_element =  torch.mean(torch.sum(1 + 2 * std_log - mean_in.pow(2) -\n",
    "                                            torch.pow(torch.exp(std_log), 2), 1))\n",
    "        return (-0.5 / num_nodes) * kld_element\n",
    "    \n",
    "    def _nll_bernoulli(self, logits, target_adj_dense):\n",
    "        temp_size = target_adj_dense.size()[0]\n",
    "        temp_sum = target_adj_dense.sum()\n",
    "        posw = float(temp_size * temp_size - temp_sum) / temp_sum\n",
    "        norm = temp_size * temp_size / float((temp_size * temp_size - temp_sum) * 2)\n",
    "        nll_loss_mat = F.binary_cross_entropy_with_logits(input=logits\n",
    "                                                          , target=target_adj_dense\n",
    "                                                          , pos_weight=posw\n",
    "                                                          , reduction='none')\n",
    "        nll_loss = -1 * norm * torch.mean(nll_loss_mat, dim=[0,1])\n",
    "        return - nll_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e79ea2df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7r/ldjcp71d7rl9t4lb3_r0llxc0000gn/T/ipykernel_94583/2716502206.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_in_list.append(torch.tensor(x_temp))\n",
      "/var/folders/7r/ldjcp71d7rl9t4lb3_r0llxc0000gn/T/ipykernel_94583/1444221298.py:18: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "  self.message_args = inspect.getargspec(self.message)[0][1:]\n",
      "/var/folders/7r/ldjcp71d7rl9t4lb3_r0llxc0000gn/T/ipykernel_94583/1444221298.py:19: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "  self.update_args = inspect.getargspec(self.update)[0][2:]\n",
      "/var/folders/7r/ldjcp71d7rl9t4lb3_r0llxc0000gn/T/ipykernel_94583/2716502206.py:56: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  nn.utils.clip_grad_norm(model.parameters(), clip)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1\n",
      "kld_loss = 0.0022042838390916586\n",
      "nll_loss = 25.72315788269043\n",
      "loss = 25.72536277770996\n",
      "----------------------------------\n",
      "epoch:  2\n",
      "kld_loss = 0.0013205519644543529\n",
      "nll_loss = 21.40664291381836\n",
      "loss = 21.407962799072266\n",
      "----------------------------------\n",
      "Link Prediction\n",
      "val_link_prd_auc_mean 0.4642105715605704\n",
      "val_link_prd_ap_mean 0.5875147180050257\n",
      "test_link_prd_auc_mean 0.45152773078479747\n",
      "test_link_prd_ap_mean 0.5727707312183434\n",
      "----------------------------------\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7r/ldjcp71d7rl9t4lb3_r0llxc0000gn/T/ipykernel_94583/2716502206.py:56: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  nn.utils.clip_grad_norm(model.parameters(), clip)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  3\n",
      "kld_loss = 0.0012449874775484204\n",
      "nll_loss = 19.784637451171875\n",
      "loss = 19.7858829498291\n",
      "----------------------------------\n",
      "Link Prediction\n",
      "val_link_prd_auc_mean 0.6536599306921291\n",
      "val_link_prd_ap_mean 0.736630946949551\n",
      "test_link_prd_auc_mean 0.6561719836026833\n",
      "test_link_prd_ap_mean 0.7364976086336664\n",
      "----------------------------------\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7r/ldjcp71d7rl9t4lb3_r0llxc0000gn/T/ipykernel_94583/2716502206.py:56: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  nn.utils.clip_grad_norm(model.parameters(), clip)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  4\n",
      "kld_loss = 0.001467072288505733\n",
      "nll_loss = 18.21546745300293\n",
      "loss = 18.216934204101562\n",
      "----------------------------------\n",
      "Link Prediction\n",
      "val_link_prd_auc_mean 0.8482485034149153\n",
      "val_link_prd_ap_mean 0.8830614116081762\n",
      "test_link_prd_auc_mean 0.855428191917086\n",
      "test_link_prd_ap_mean 0.8896208558112038\n",
      "----------------------------------\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7r/ldjcp71d7rl9t4lb3_r0llxc0000gn/T/ipykernel_94583/2716502206.py:56: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  nn.utils.clip_grad_norm(model.parameters(), clip)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  5\n",
      "kld_loss = 0.0018997460138052702\n",
      "nll_loss = 17.09881019592285\n",
      "loss = 17.100709915161133\n",
      "----------------------------------\n",
      "Link Prediction\n",
      "val_link_prd_auc_mean 0.899468828776556\n",
      "val_link_prd_ap_mean 0.9227204128405178\n",
      "test_link_prd_auc_mean 0.8936665062662823\n",
      "test_link_prd_ap_mean 0.9206302298026308\n",
      "----------------------------------\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7r/ldjcp71d7rl9t4lb3_r0llxc0000gn/T/ipykernel_94583/2716502206.py:56: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  nn.utils.clip_grad_norm(model.parameters(), clip)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  6\n",
      "kld_loss = 0.0020023949909955263\n",
      "nll_loss = 16.06248664855957\n",
      "loss = 16.064489364624023\n",
      "----------------------------------\n",
      "Link Prediction\n",
      "val_link_prd_auc_mean 0.8968687500031335\n",
      "val_link_prd_ap_mean 0.9235899808285767\n",
      "test_link_prd_auc_mean 0.9066067168314562\n",
      "test_link_prd_ap_mean 0.9298278043711399\n",
      "----------------------------------\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7r/ldjcp71d7rl9t4lb3_r0llxc0000gn/T/ipykernel_94583/2716502206.py:56: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  nn.utils.clip_grad_norm(model.parameters(), clip)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  7\n",
      "kld_loss = 0.0017281223554164171\n",
      "nll_loss = 14.500131607055664\n",
      "loss = 14.501859664916992\n",
      "----------------------------------\n",
      "Link Prediction\n",
      "val_link_prd_auc_mean 0.9218601106198451\n",
      "val_link_prd_ap_mean 0.9388505852249431\n",
      "test_link_prd_auc_mean 0.9081896756631787\n",
      "test_link_prd_ap_mean 0.930745442891173\n",
      "----------------------------------\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7r/ldjcp71d7rl9t4lb3_r0llxc0000gn/T/ipykernel_94583/2716502206.py:56: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  nn.utils.clip_grad_norm(model.parameters(), clip)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  8\n",
      "kld_loss = 0.0017911359900608659\n",
      "nll_loss = 13.119743347167969\n",
      "loss = 13.12153434753418\n",
      "----------------------------------\n",
      "Link Prediction\n",
      "val_link_prd_auc_mean 0.9093151581159229\n",
      "val_link_prd_ap_mean 0.9324052798217433\n",
      "test_link_prd_auc_mean 0.9010205728458411\n",
      "test_link_prd_ap_mean 0.9276485315899037\n",
      "----------------------------------\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7r/ldjcp71d7rl9t4lb3_r0llxc0000gn/T/ipykernel_94583/2716502206.py:56: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  nn.utils.clip_grad_norm(model.parameters(), clip)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  9\n",
      "kld_loss = 0.002328465459868312\n",
      "nll_loss = 12.025131225585938\n",
      "loss = 12.027460098266602\n",
      "----------------------------------\n",
      "Link Prediction\n",
      "val_link_prd_auc_mean 0.9319870314988667\n",
      "val_link_prd_ap_mean 0.9460308606535351\n",
      "test_link_prd_auc_mean 0.923871543555022\n",
      "test_link_prd_ap_mean 0.9418859282524996\n",
      "----------------------------------\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7r/ldjcp71d7rl9t4lb3_r0llxc0000gn/T/ipykernel_94583/2716502206.py:56: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  nn.utils.clip_grad_norm(model.parameters(), clip)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  10\n",
      "kld_loss = 0.003241379978135228\n",
      "nll_loss = 11.306328773498535\n",
      "loss = 11.3095703125\n",
      "----------------------------------\n",
      "Link Prediction\n",
      "val_link_prd_auc_mean 0.8996606680541588\n",
      "val_link_prd_ap_mean 0.9291746381143928\n",
      "test_link_prd_auc_mean 0.893007472667949\n",
      "test_link_prd_ap_mean 0.9255437439972574\n",
      "----------------------------------\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7r/ldjcp71d7rl9t4lb3_r0llxc0000gn/T/ipykernel_94583/2716502206.py:56: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  nn.utils.clip_grad_norm(model.parameters(), clip)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  11\n",
      "kld_loss = 0.004354794044047594\n",
      "nll_loss = 10.94332504272461\n",
      "loss = 10.94767951965332\n",
      "----------------------------------\n",
      "Link Prediction\n",
      "val_link_prd_auc_mean 0.9156904974397625\n",
      "val_link_prd_ap_mean 0.9368495356237552\n",
      "test_link_prd_auc_mean 0.9138981756506297\n",
      "test_link_prd_ap_mean 0.9351427419963678\n",
      "----------------------------------\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7r/ldjcp71d7rl9t4lb3_r0llxc0000gn/T/ipykernel_94583/2716502206.py:56: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  nn.utils.clip_grad_norm(model.parameters(), clip)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  12\n",
      "kld_loss = 0.005116147920489311\n",
      "nll_loss = 10.609411239624023\n",
      "loss = 10.614527702331543\n",
      "----------------------------------\n",
      "Link Prediction\n",
      "val_link_prd_auc_mean 0.8929399778558962\n",
      "val_link_prd_ap_mean 0.9243801787782417\n",
      "test_link_prd_auc_mean 0.889298964847526\n",
      "test_link_prd_ap_mean 0.9227214752214015\n",
      "----------------------------------\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7r/ldjcp71d7rl9t4lb3_r0llxc0000gn/T/ipykernel_94583/2716502206.py:56: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  nn.utils.clip_grad_norm(model.parameters(), clip)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  13\n",
      "kld_loss = 0.005517151206731796\n",
      "nll_loss = 10.217734336853027\n",
      "loss = 10.223251342773438\n",
      "----------------------------------\n",
      "Link Prediction\n",
      "val_link_prd_auc_mean 0.8998821419569454\n",
      "val_link_prd_ap_mean 0.9262449687071626\n",
      "test_link_prd_auc_mean 0.8981589518466949\n",
      "test_link_prd_ap_mean 0.9252879261096429\n",
      "----------------------------------\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7r/ldjcp71d7rl9t4lb3_r0llxc0000gn/T/ipykernel_94583/2716502206.py:56: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  nn.utils.clip_grad_norm(model.parameters(), clip)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  14\n",
      "kld_loss = 0.005889405962079763\n",
      "nll_loss = 9.76919174194336\n",
      "loss = 9.775080680847168\n",
      "----------------------------------\n",
      "Link Prediction\n",
      "val_link_prd_auc_mean 0.8946752189851345\n",
      "val_link_prd_ap_mean 0.9242594635528408\n",
      "test_link_prd_auc_mean 0.8909143218582636\n",
      "test_link_prd_ap_mean 0.9214981036418638\n",
      "----------------------------------\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7r/ldjcp71d7rl9t4lb3_r0llxc0000gn/T/ipykernel_94583/2716502206.py:56: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  nn.utils.clip_grad_norm(model.parameters(), clip)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  15\n",
      "kld_loss = 0.006366121117025614\n",
      "nll_loss = 9.374669075012207\n",
      "loss = 9.381034851074219\n",
      "----------------------------------\n",
      "Link Prediction\n",
      "val_link_prd_auc_mean 0.8981946341694724\n",
      "val_link_prd_ap_mean 0.9248068784348662\n",
      "test_link_prd_auc_mean 0.8949861197878034\n",
      "test_link_prd_ap_mean 0.9221933580062583\n",
      "----------------------------------\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7r/ldjcp71d7rl9t4lb3_r0llxc0000gn/T/ipykernel_94583/2716502206.py:56: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  nn.utils.clip_grad_norm(model.parameters(), clip)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  16\n",
      "kld_loss = 0.006975248921662569\n",
      "nll_loss = 9.043909072875977\n",
      "loss = 9.050884246826172\n",
      "----------------------------------\n",
      "Link Prediction\n",
      "val_link_prd_auc_mean 0.8906099439756416\n",
      "val_link_prd_ap_mean 0.9183587816830596\n",
      "test_link_prd_auc_mean 0.8849880947359651\n",
      "test_link_prd_ap_mean 0.9162242021487056\n",
      "----------------------------------\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7r/ldjcp71d7rl9t4lb3_r0llxc0000gn/T/ipykernel_94583/2716502206.py:56: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  nn.utils.clip_grad_norm(model.parameters(), clip)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  17\n",
      "kld_loss = 0.007644736673682928\n",
      "nll_loss = 8.749134063720703\n",
      "loss = 8.756778717041016\n",
      "----------------------------------\n",
      "Link Prediction\n",
      "val_link_prd_auc_mean 0.8909108100610461\n",
      "val_link_prd_ap_mean 0.9183744913410643\n",
      "test_link_prd_auc_mean 0.8897008360624556\n",
      "test_link_prd_ap_mean 0.9188098496400495\n",
      "----------------------------------\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7r/ldjcp71d7rl9t4lb3_r0llxc0000gn/T/ipykernel_94583/2716502206.py:56: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  nn.utils.clip_grad_norm(model.parameters(), clip)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  18\n",
      "kld_loss = 0.008444410748779774\n",
      "nll_loss = 8.523386001586914\n",
      "loss = 8.531830787658691\n",
      "----------------------------------\n",
      "Link Prediction\n",
      "val_link_prd_auc_mean 0.8763708171023185\n",
      "val_link_prd_ap_mean 0.9110141356100611\n",
      "test_link_prd_auc_mean 0.8598931191298859\n",
      "test_link_prd_ap_mean 0.9037994772472557\n",
      "----------------------------------\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7r/ldjcp71d7rl9t4lb3_r0llxc0000gn/T/ipykernel_94583/2716502206.py:56: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  nn.utils.clip_grad_norm(model.parameters(), clip)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping: Validation AUC and Loss haven't improved in 10 epochs.\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "h_dim = 32\n",
    "z_dim = 16\n",
    "n_layers =  1\n",
    "clip = 10\n",
    "learning_rate = 1e-2\n",
    "seq_len = len(train_edges_l) # Number of Snapshots\n",
    "num_nodes = adj_orig_dense_list[seq_len-1].shape[0] #number of node in the graph\n",
    "x_dim = num_nodes\n",
    "eps = 1e-10\n",
    "conv_type='GCN'\n",
    "\n",
    "\n",
    "# creating input tensors\n",
    "x_in_list = []\n",
    "for i in range(0, seq_len):\n",
    "    x_temp = torch.tensor(np.eye(num_nodes).astype(np.float32))\n",
    "    x_in_list.append(torch.tensor(x_temp))\n",
    "\n",
    "x_in = Variable(torch.stack(x_in_list))\n",
    "\n",
    "\n",
    "# building model\n",
    "model = VGRNN(x_dim, h_dim, z_dim, n_layers, eps, conv=conv_type, bias=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "# training\n",
    "seq_start = 0\n",
    "seq_end = seq_len - 9\n",
    "tst_after = 0\n",
    "\n",
    "\n",
    "# Define variables to track best performance and early stopping\n",
    "best_val_metric = -float('inf')  # Initialize with negative infinity\n",
    "best_loss = float('inf')\n",
    "epochs_since_best = 0\n",
    "patience = 10  # Number of epochs to wait before stopping\n",
    "\n",
    "\n",
    "loss_values = []\n",
    "auc_values = []\n",
    "\n",
    "\n",
    "for k in range(50):\n",
    "    optimizer.zero_grad()\n",
    "    start_time = time.time()\n",
    "    kld_loss, nll_loss, _, _, hidden_st = model(x_in[seq_start:seq_end]\n",
    "                                                    , edge_idx_list[seq_start:seq_end]\n",
    "                                                    , adj_orig_dense_list[seq_start:seq_end])\n",
    "    loss = kld_loss + nll_loss\n",
    "    loss_values.append(loss.mean().item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "     \n",
    "    nn.utils.clip_grad_norm(model.parameters(), clip)\n",
    "        \n",
    "\n",
    "    \n",
    "    if k>tst_after:\n",
    "        _, _, _, pri_means, _ = model(x_in[seq_end:seq_len]\n",
    "                                                  , edge_idx_list[seq_end:seq_len]\n",
    "                                                  , adj_orig_dense_list[seq_end:seq_len]\n",
    "                                                  , hidden_st)\n",
    "\n",
    "        auc_scores_det_val, ap_scores_det_val = get_roc_scores(val_edges_l[seq_end:seq_len]\n",
    "                                                                , val_edges_false_l[seq_end:seq_len]\n",
    "                                                                , adj_orig_dense_list[seq_end:seq_len]\n",
    "                                                                , pri_means)\n",
    "\n",
    "        \n",
    "        mean_val_metric = np.mean(np.array(auc_scores_det_val))\n",
    "\n",
    "        # Check if the current validation performance is better than the best\n",
    "#         if mean_val_metric > best_val_metric or loss.mean().item() < best_loss:\n",
    "#             best_val_metric = mean_val_metric\n",
    "#             best_loss = loss.mean().item()\n",
    "        if mean_val_metric > best_val_metric:\n",
    "            best_val_metric = mean_val_metric\n",
    "            epochs_since_best = 0  # Reset the counter since performance improved\n",
    "        else:\n",
    "            epochs_since_best += 1\n",
    "\n",
    "        # Check if early stopping criteria are met based on both validation AUC and loss\n",
    "        if epochs_since_best >= patience:\n",
    "            print(\"Early stopping: Validation AUC and Loss haven't improved in {} epochs.\".format(patience))\n",
    "            break  # Stop training\n",
    "            \n",
    "        auc_scores_det_test, ap_scores_det_tes = get_roc_scores(test_edges_l[seq_end:seq_len]\n",
    "                                                                , test_edges_false_l[seq_end:seq_len]\n",
    "                                                                , adj_orig_dense_list[seq_end:seq_len]\n",
    "                                                                , pri_means)\n",
    "        auc_values.append(np.mean(np.array(auc_scores_det_test)))\n",
    "        \n",
    "    print('epoch: ', k+1)\n",
    "    print('kld_loss =', kld_loss.mean().item())\n",
    "    print('nll_loss =', nll_loss.mean().item())\n",
    "    print('loss =', loss.mean().item())\n",
    "    if k>tst_after:\n",
    "        print('----------------------------------')\n",
    "        print('Link Prediction')\n",
    "        print('val_link_prd_auc_mean', np.mean(np.array(auc_scores_det_val)))\n",
    "        print('val_link_prd_ap_mean', np.mean(np.array(ap_scores_det_val)))\n",
    "        print('test_link_prd_auc_mean', np.mean(np.array(auc_scores_det_test)))\n",
    "        print('test_link_prd_ap_mean', np.mean(np.array(ap_scores_det_tes)))\n",
    "        print('----------------------------------')\n",
    "    print('----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd2c5b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the curves\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "# Plot test AUC curve on the left y-axis\n",
    "ax1.plot(auc_values[:17], label='Test AUC', color='orange')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('AUC')\n",
    "ax1.tick_params(axis='y')\n",
    "ax1.set_title('VGRNN Training Loss and Test AUC - Day')\n",
    "#ax1.set_ylim(0, 1)\n",
    "\n",
    "# Ensure x-axis ticks are integers\n",
    "ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# Create a twin Axes sharing the xaxis with test AUC curve\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot training loss curve on the right y-axis\n",
    "ax2.plot(loss_values[:16], label='Training Loss', color='blue')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.tick_params(axis='y')\n",
    "\n",
    "# Display legends for both curves\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines + lines2, labels + labels2, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26f18d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
